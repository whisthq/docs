<!DOCTYPE html><html><head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<meta name="theme-color" content="#375EAB"/>

  <title>src/github.com/fractal/fractal/host-service/metrics/metrics.go - Fractal Host Service</title>

<link type="text/css" rel="stylesheet" href="https://docs.fractal.co/host-service//lib/godoc/style.css"/>

<script>window.initFuncs = [];</script>
<script src="https://docs.fractal.co/host-service//lib/godoc/jquery.js" defer=""></script>




<script>var goVersion = "go1.17.2";</script>
<script src="https://docs.fractal.co/host-service//lib/godoc/godocs.js" defer=""></script>
</head>
<body>

<div id="lowframe" style="position: fixed; bottom: 0; left: 0; height: 0; width: 100%; border-top: thin solid grey; background-color: white; overflow: auto;">
...
</div><!-- #lowframe -->

<div id="topbar" class="wide"><div class="container">
<div class="top-heading" id="heading-wide"><a href="https:/docs.fractal.co/host-service/pkg/github.com/fractal/fractal/host-service/">Fractal Host Service | Autogenerated from 56fcca5</a></div>
<div class="top-heading" id="heading-narrow"><a href="https:/docs.fractal.co/host-service/pkg/github.com/fractal/fractal/host-service/">Fractal Host Service</a></div>
<a href="#" id="menu-button"><span id="menu-button-arrow">▽</span></a>

</div></div>



<div id="page" class="wide">
<div class="container">


  <h1>
    Source file
    <a href="https:/docs.fractal.co/host-service/src">src</a>/<a href="https:/docs.fractal.co/host-service/src/github.com">github.com</a>/<a href="https:/docs.fractal.co/host-service/src/github.com/fractal">fractal</a>/<a href="https:/docs.fractal.co/host-service/src/github.com/fractal/fractal">fractal</a>/<a href="https:/docs.fractal.co/host-service/src/github.com/fractal/fractal/host-service">host-service</a>/<a href="https:/docs.fractal.co/host-service/src/github.com/fractal/fractal/host-service/metrics">metrics</a>/<span class="text-muted">metrics.go</span>
  </h1>





  <h2>
    Documentation: <a href="https:/docs.fractal.co/host-service/pkg/github.com/fractal/fractal/host-service/metrics">github.com/fractal/fractal/host-service/metrics</a>
  </h2>



<div id="nav"></div>


<script type="text/javascript">document.ANALYSIS_DATA = null;</script>
<pre><span id="L1" class="ln">     1  </span><span class="comment">/*
<span id="L2" class="ln">     2  </span>Package metrics is responsible for computing metrics about the instance during
<span id="L3" class="ln">     3  </span>host service runtime. This includes metrics about total load, CPU usage, etc.
<span id="L4" class="ln">     4  </span>*/</span>
<span id="L5" class="ln">     5  </span>package metrics <span class="comment">// import &#34;github.com/fractal/fractal/host-service/metrics&#34;</span>
<span id="L6" class="ln">     6  </span>
<span id="L7" class="ln">     7  </span>import (
<span id="L8" class="ln">     8  </span>	&#34;math/rand&#34;
<span id="L9" class="ln">     9  </span>	&#34;sync&#34;
<span id="L10" class="ln">    10  </span>	&#34;time&#34;
<span id="L11" class="ln">    11  </span>
<span id="L12" class="ln">    12  </span>	logger &#34;github.com/fractal/fractal/host-service/fractallogger&#34;
<span id="L13" class="ln">    13  </span>	&#34;github.com/fractal/fractal/host-service/metadata&#34;
<span id="L14" class="ln">    14  </span>	&#34;github.com/fractal/fractal/host-service/utils&#34;
<span id="L15" class="ln">    15  </span>
<span id="L16" class="ln">    16  </span>	&#34;github.com/NVIDIA/go-nvml/pkg/nvml&#34;
<span id="L17" class="ln">    17  </span>
<span id="L18" class="ln">    18  </span>	&#34;github.com/shirou/gopsutil/cpu&#34;
<span id="L19" class="ln">    19  </span>	&#34;github.com/shirou/gopsutil/disk&#34;
<span id="L20" class="ln">    20  </span>	&#34;github.com/shirou/gopsutil/host&#34;
<span id="L21" class="ln">    21  </span>	&#34;github.com/shirou/gopsutil/load&#34;
<span id="L22" class="ln">    22  </span>	&#34;github.com/shirou/gopsutil/mem&#34;
<span id="L23" class="ln">    23  </span>)
<span id="L24" class="ln">    24  </span>
<span id="L25" class="ln">    25  </span><span class="comment">// A RuntimeMetrics groups together several pieces of useful information about</span>
<span id="L26" class="ln">    26  </span><span class="comment">// the underlying host.</span>
<span id="L27" class="ln">    27  </span>type RuntimeMetrics struct {
<span id="L28" class="ln">    28  </span>	<span class="comment">// Memory</span>
<span id="L29" class="ln">    29  </span>
<span id="L30" class="ln">    30  </span>	<span class="comment">// TotalMemoryKB represents the total amount of memory on the host, in KB.</span>
<span id="L31" class="ln">    31  </span>	TotalMemoryKB uint64
<span id="L32" class="ln">    32  </span>
<span id="L33" class="ln">    33  </span>	<span class="comment">// FreeMemoryKB represents the amount of currently free memory on the host,</span>
<span id="L34" class="ln">    34  </span>	<span class="comment">// in KB. This is a lower bound for how much more memory we can theoretically</span>
<span id="L35" class="ln">    35  </span>	<span class="comment">// use, since some cached files can be evicted to free up some more memory.</span>
<span id="L36" class="ln">    36  </span>	FreeMemoryKB uint64
<span id="L37" class="ln">    37  </span>
<span id="L38" class="ln">    38  </span>	<span class="comment">// AvailableMemoryKB represents the amount of currently available memory in</span>
<span id="L39" class="ln">    39  </span>	<span class="comment">// the host in KB. This is a hard upper bound for how much more memory we can</span>
<span id="L40" class="ln">    40  </span>	<span class="comment">// use before we start swapping or crash. We should allocate well below this</span>
<span id="L41" class="ln">    41  </span>	<span class="comment">// number because performance will suffer long before we get here.</span>
<span id="L42" class="ln">    42  </span>	AvailableMemoryKB uint64
<span id="L43" class="ln">    43  </span>
<span id="L44" class="ln">    44  </span>	<span class="comment">// CPU</span>
<span id="L45" class="ln">    45  </span>
<span id="L46" class="ln">    46  </span>	<span class="comment">// LogicalCPUs represents the number of logical CPUs on the host when the</span>
<span id="L47" class="ln">    47  </span>	<span class="comment">// host service was started.</span>
<span id="L48" class="ln">    48  </span>	LogicalCPUs int
<span id="L49" class="ln">    49  </span>
<span id="L50" class="ln">    50  </span>	<span class="comment">// CPUUtilizationPercent represents the percentage of total CPU utilization</span>
<span id="L51" class="ln">    51  </span>	<span class="comment">// across the host system.</span>
<span id="L52" class="ln">    52  </span>	CPUUtilizationPercent float64
<span id="L53" class="ln">    53  </span>
<span id="L54" class="ln">    54  </span>	<span class="comment">// NanoCPUsRemaining represents the amount of CPU remaining in units of</span>
<span id="L55" class="ln">    55  </span>	<span class="comment">// (10^-9 CPU). In other words, if two cores are fully idle and all others</span>
<span id="L56" class="ln">    56  </span>	<span class="comment">// are at maximum usage, there&#39;s 2*10^9 NanoCPUsRemaining on that instance.</span>
<span id="L57" class="ln">    57  </span>	NanoCPUsRemaining uint64
<span id="L58" class="ln">    58  </span>
<span id="L59" class="ln">    59  </span>	<span class="comment">// GPU</span>
<span id="L60" class="ln">    60  </span>
<span id="L61" class="ln">    61  </span>	<span class="comment">// NumberOfGPUs represents the number of NVIDIA GPUs on the host system. Note</span>
<span id="L62" class="ln">    62  </span>	<span class="comment">// that for now we assume that all GPUs on an instance are homogeneous.</span>
<span id="L63" class="ln">    63  </span>	NumberOfGPUs int
<span id="L64" class="ln">    64  </span>
<span id="L65" class="ln">    65  </span>	<span class="comment">// TotalVideoMemoryKB represents the amount of video memory in total across</span>
<span id="L66" class="ln">    66  </span>	<span class="comment">// all GPUs on the instance.</span>
<span id="L67" class="ln">    67  </span>	TotalVideoMemoryKB uint64
<span id="L68" class="ln">    68  </span>
<span id="L69" class="ln">    69  </span>	<span class="comment">// UsedVideoMemoryKB represents the amount of in-use video memory totaled</span>
<span id="L70" class="ln">    70  </span>	<span class="comment">// across all GPUs on the instance.</span>
<span id="L71" class="ln">    71  </span>	UsedVideoMemoryKB uint64
<span id="L72" class="ln">    72  </span>
<span id="L73" class="ln">    73  </span>	<span class="comment">// FreeVideoMemoryKB represents the amount of video memory remaining in</span>
<span id="L74" class="ln">    74  </span>	<span class="comment">// total across all GPUs on the instance.</span>
<span id="L75" class="ln">    75  </span>	FreeVideoMemoryKB uint64
<span id="L76" class="ln">    76  </span>
<span id="L77" class="ln">    77  </span>	<span class="comment">// GPUUtilizationPercent represents (an imprecise estimate of) the percentage</span>
<span id="L78" class="ln">    78  </span>	<span class="comment">// of time the GPUs recently spent on GPU kernel computations (this does not</span>
<span id="L79" class="ln">    79  </span>	<span class="comment">// refer to the Linux kernel, but rather kernels that can run on a GPU).</span>
<span id="L80" class="ln">    80  </span>	GPUKernelUtilizationPercent float64
<span id="L81" class="ln">    81  </span>
<span id="L82" class="ln">    82  </span>	<span class="comment">// GPUMemoryBandwidthUtilizationPercent represents (an imprecise estimate of)</span>
<span id="L83" class="ln">    83  </span>	<span class="comment">// the percentage of time recently when the GPU&#39;s memory was being written</span>
<span id="L84" class="ln">    84  </span>	<span class="comment">// to.</span>
<span id="L85" class="ln">    85  </span>	GPUMemoryBandwidthUtilizationPercent float64
<span id="L86" class="ln">    86  </span>
<span id="L87" class="ln">    87  </span>	<span class="comment">// Load Averages</span>
<span id="L88" class="ln">    88  </span>
<span id="L89" class="ln">    89  </span>	<span class="comment">// For an explanation of what these mean, see</span>
<span id="L90" class="ln">    90  </span>	<span class="comment">// https://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html</span>
<span id="L91" class="ln">    91  </span>	LoadAverage1Min  float64
<span id="L92" class="ln">    92  </span>	LoadAverage5Min  float64
<span id="L93" class="ln">    93  </span>	LoadAverage15Min float64
<span id="L94" class="ln">    94  </span>
<span id="L95" class="ln">    95  </span>	<span class="comment">// Disk Usage</span>
<span id="L96" class="ln">    96  </span>
<span id="L97" class="ln">    97  </span>	<span class="comment">// DiskTotalKB represents the total amount of SSD space available to the</span>
<span id="L98" class="ln">    98  </span>	<span class="comment">// host.</span>
<span id="L99" class="ln">    99  </span>	DiskTotalKB uint64
<span id="L100" class="ln">   100  </span>
<span id="L101" class="ln">   101  </span>	<span class="comment">// DiskUsedKB represents the total amount of SSD space in use on the host.</span>
<span id="L102" class="ln">   102  </span>	DiskUsedKB uint64
<span id="L103" class="ln">   103  </span>
<span id="L104" class="ln">   104  </span>	<span class="comment">// DiskFreeKB represents the total amount of SSD space free on the host.</span>
<span id="L105" class="ln">   105  </span>	DiskFreeKB uint64
<span id="L106" class="ln">   106  </span>
<span id="L107" class="ln">   107  </span>	<span class="comment">// DiskUsedPercent represents the percentage of disk space used on the host.</span>
<span id="L108" class="ln">   108  </span>	DiskUsedPercent float64
<span id="L109" class="ln">   109  </span>
<span id="L110" class="ln">   110  </span>	<span class="comment">// Time</span>
<span id="L111" class="ln">   111  </span>
<span id="L112" class="ln">   112  </span>	<span class="comment">// Uptime represents how long the current instance has been up, at a</span>
<span id="L113" class="ln">   113  </span>	<span class="comment">// granularity of one second.</span>
<span id="L114" class="ln">   114  </span>	Uptime time.Duration
<span id="L115" class="ln">   115  </span>
<span id="L116" class="ln">   116  </span>	<span class="comment">// TimeStamp denotes the timestamp when the values in this struct were</span>
<span id="L117" class="ln">   117  </span>	<span class="comment">// collected. This can be used by callers of `GetLatest` to determine how</span>
<span id="L118" class="ln">   118  </span>	<span class="comment">// out-of-date the stats are.</span>
<span id="L119" class="ln">   119  </span>	TimeStamp time.Time
<span id="L120" class="ln">   120  </span>}
<span id="L121" class="ln">   121  </span>
<span id="L122" class="ln">   122  </span>func init() {
<span id="L123" class="ln">   123  </span>	if !metadata.IsRunningInCI() {
<span id="L124" class="ln">   124  </span>		err := startCollectionGoroutine(30 * time.Second)
<span id="L125" class="ln">   125  </span>		if err != nil {
<span id="L126" class="ln">   126  </span>			<span class="comment">// We can safely do a &#34;real&#34; panic in an init function.</span>
<span id="L127" class="ln">   127  </span>			logger.Panicf(nil, &#34;Error starting metrics collection goroutine: %s&#34;, err)
<span id="L128" class="ln">   128  </span>		}
<span id="L129" class="ln">   129  </span>	} else {
<span id="L130" class="ln">   130  </span>		logger.Info(&#34;Skipping metrics collection in CI&#34;)
<span id="L131" class="ln">   131  </span>	}
<span id="L132" class="ln">   132  </span>}
<span id="L133" class="ln">   133  </span>
<span id="L134" class="ln">   134  </span><span class="comment">// As long as this channel is blocking, we should keep collecting metrics. As</span>
<span id="L135" class="ln">   135  </span><span class="comment">// soon as the channel is closed, we stop collecting metrics.</span>
<span id="L136" class="ln">   136  </span>var collectionKeepAlive = make(chan interface{}, 1)
<span id="L137" class="ln">   137  </span>
<span id="L138" class="ln">   138  </span><span class="comment">// startCollectionGoroutine starts a goroutine that regularly computes metrics about the</span>
<span id="L139" class="ln">   139  </span><span class="comment">// host and caches the most recent result. This prevents requests for metrics</span>
<span id="L140" class="ln">   140  </span><span class="comment">// (like average CPU usage) from blocking, since this goroutine can do the</span>
<span id="L141" class="ln">   141  </span><span class="comment">// blocking instead. The frequency passed must be at least 1.5 seconds to avoid</span>
<span id="L142" class="ln">   142  </span><span class="comment">// performance issues, and to allow for adding a random jitter to the</span>
<span id="L143" class="ln">   143  </span><span class="comment">// frequency. Note that you must wait for StartCollection to return</span>
<span id="L144" class="ln">   144  </span><span class="comment">// successfully before calling any metrics-retrieving functions.</span>
<span id="L145" class="ln">   145  </span>func startCollectionGoroutine(frequency time.Duration) error {
<span id="L146" class="ln">   146  </span>	if frequency &lt; 1500*time.Millisecond {
<span id="L147" class="ln">   147  </span>		return utils.MakeError(&#34;The frequency passed to StartMetricsCollection must be at least one 1.5 seconds to avoid performance issues.&#34;)
<span id="L148" class="ln">   148  </span>	}
<span id="L149" class="ln">   149  </span>
<span id="L150" class="ln">   150  </span>	<span class="comment">// Initialize necessary libraries (i.e. NVML). Don&#39;t forget to uninitialize</span>
<span id="L151" class="ln">   151  </span>	<span class="comment">// them below (we can&#39;t use defer here since we&#39;re returning from this</span>
<span id="L152" class="ln">   152  </span>	<span class="comment">// function).</span>
<span id="L153" class="ln">   153  </span>	if nvmlRet := nvml.Init(); nvmlRet != nvml.SUCCESS {
<span id="L154" class="ln">   154  </span>		return utils.MakeError(&#34;Unable to initialize NVML for metrics collection.&#34;)
<span id="L155" class="ln">   155  </span>	}
<span id="L156" class="ln">   156  </span>
<span id="L157" class="ln">   157  </span>	<span class="comment">// We do the first batch of metrics collection before returning, so that any</span>
<span id="L158" class="ln">   158  </span>	<span class="comment">// calls to metrics-retrieving functions after StartMetricsCollection returns</span>
<span id="L159" class="ln">   159  </span>	<span class="comment">// are guaranteed to succeed. Note that the very first batch of CPU data is</span>
<span id="L160" class="ln">   160  </span>	<span class="comment">// not likely to be accurate, since we&#39;re measuring over a zero-length</span>
<span id="L161" class="ln">   161  </span>	<span class="comment">// interval, but this is not a big deal. We also don&#39;t have to worry about</span>
<span id="L162" class="ln">   162  </span>	<span class="comment">// locking here, since clients of this library are required to call</span>
<span id="L163" class="ln">   163  </span>	<span class="comment">// StartCollection before anything else.</span>
<span id="L164" class="ln">   164  </span>	latestMetrics, latestErrors = collectOnce()
<span id="L165" class="ln">   165  </span>	if len(latestErrors) != 0 {
<span id="L166" class="ln">   166  </span>		return utils.MakeError(&#34;Errors collecting the first batch of metrics: %v&#34;, latestErrors)
<span id="L167" class="ln">   167  </span>	}
<span id="L168" class="ln">   168  </span>
<span id="L169" class="ln">   169  </span>	<span class="comment">// Start the metrics collection goroutine</span>
<span id="L170" class="ln">   170  </span>	go func() {
<span id="L171" class="ln">   171  </span>		logger.Infof(&#34;Starting metrics collection goroutine.&#34;)
<span id="L172" class="ln">   172  </span>		timerChan := make(chan interface{})
<span id="L173" class="ln">   173  </span>
<span id="L174" class="ln">   174  </span>		for {
<span id="L175" class="ln">   175  </span>			<span class="comment">// We add some jitter to this sleeptime to avoid unintended effects or</span>
<span id="L176" class="ln">   176  </span>			<span class="comment">// patterns from recording data at a constant frequency.</span>
<span id="L177" class="ln">   177  </span>			sleepTime := frequency + time.Second - time.Duration(rand.Intn(2000))*time.Millisecond
<span id="L178" class="ln">   178  </span>			timer := time.AfterFunc(sleepTime, func() { timerChan &lt;- struct{}{} })
<span id="L179" class="ln">   179  </span>
<span id="L180" class="ln">   180  </span>			select {
<span id="L181" class="ln">   181  </span>			case _, _ = &lt;-collectionKeepAlive:
<span id="L182" class="ln">   182  </span>				<span class="comment">// If we hit this case, that means that `collectionKeepAlive` was either</span>
<span id="L183" class="ln">   183  </span>				<span class="comment">// closed or written to (it should not be written to), but either way,</span>
<span id="L184" class="ln">   184  </span>				<span class="comment">// it&#39;s time to die.</span>
<span id="L185" class="ln">   185  </span>
<span id="L186" class="ln">   186  </span>				logger.Infof(&#34;Shutting down metrics collection goroutine.&#34;)
<span id="L187" class="ln">   187  </span>
<span id="L188" class="ln">   188  </span>				<span class="comment">// Uninitialize libraries (i.e. NVML).</span>
<span id="L189" class="ln">   189  </span>				if nvmlRet := nvml.Shutdown(); nvmlRet != nvml.SUCCESS {
<span id="L190" class="ln">   190  </span>					logger.Errorf(&#34;Error shutting down NVML library.&#34;)
<span id="L191" class="ln">   191  </span>				}
<span id="L192" class="ln">   192  </span>
<span id="L193" class="ln">   193  </span>				<span class="comment">// Stop timer to avoid leaking a goroutine (not that it matters if we&#39;re</span>
<span id="L194" class="ln">   194  </span>				<span class="comment">// shutting down, but still).</span>
<span id="L195" class="ln">   195  </span>				<span class="comment">// (https://golang.org/pkg/time/#Timer.Stop)</span>
<span id="L196" class="ln">   196  </span>				if !timer.Stop() {
<span id="L197" class="ln">   197  </span>					&lt;-timer.C
<span id="L198" class="ln">   198  </span>				}
<span id="L199" class="ln">   199  </span>				return
<span id="L200" class="ln">   200  </span>
<span id="L201" class="ln">   201  </span>			case _ = &lt;-timerChan:
<span id="L202" class="ln">   202  </span>				<span class="comment">// Time to collect some metrics</span>
<span id="L203" class="ln">   203  </span>				newMetrics, errs := collectOnce()
<span id="L204" class="ln">   204  </span>
<span id="L205" class="ln">   205  </span>				latestLock.Lock()
<span id="L206" class="ln">   206  </span>				latestMetrics, latestErrors = newMetrics, errs
<span id="L207" class="ln">   207  </span>				latestLock.Unlock()
<span id="L208" class="ln">   208  </span>
<span id="L209" class="ln">   209  </span>				<span class="comment">// TODO: re-enable this once we can send metrics to logz but not print to standard output</span>
<span id="L210" class="ln">   210  </span>				<span class="comment">// logger.Infof(&#34;Collected latest metrics: %+v&#34;, newMetrics)</span>
<span id="L211" class="ln">   211  </span>				if len(latestErrors) != 0 {
<span id="L212" class="ln">   212  </span>					logger.Errorf(&#34;Errors collecting latest metrics: %v&#34;, latestErrors)
<span id="L213" class="ln">   213  </span>				}
<span id="L214" class="ln">   214  </span>			}
<span id="L215" class="ln">   215  </span>		}
<span id="L216" class="ln">   216  </span>	}()
<span id="L217" class="ln">   217  </span>
<span id="L218" class="ln">   218  </span>	return nil
<span id="L219" class="ln">   219  </span>}
<span id="L220" class="ln">   220  </span>
<span id="L221" class="ln">   221  </span><span class="comment">// latestMetrics is the cache of the most recently measured metrics.</span>
<span id="L222" class="ln">   222  </span>var latestMetrics RuntimeMetrics
<span id="L223" class="ln">   223  </span>
<span id="L224" class="ln">   224  </span><span class="comment">// latestErrors is the cache of errors encountered while collecting the most</span>
<span id="L225" class="ln">   225  </span><span class="comment">// recently measured metrics.</span>
<span id="L226" class="ln">   226  </span>var latestErrors []error
<span id="L227" class="ln">   227  </span>
<span id="L228" class="ln">   228  </span><span class="comment">// latestLock protects latestMetrics and latestErrors so that they can be updated and read concurrently.</span>
<span id="L229" class="ln">   229  </span>var latestLock sync.Mutex
<span id="L230" class="ln">   230  </span>
<span id="L231" class="ln">   231  </span><span class="comment">// collectOnce attempts to collect all the metrics it can, and caches</span>
<span id="L232" class="ln">   232  </span><span class="comment">// the results in `latestMetrics`. It also returns a slice of all the errors</span>
<span id="L233" class="ln">   233  </span><span class="comment">// that it encountered. This is by design, since we don&#39;t want a single error</span>
<span id="L234" class="ln">   234  </span><span class="comment">// to prevent the collection of all metrics. In other words, this function</span>
<span id="L235" class="ln">   235  </span><span class="comment">// tries to recover and do as much as it can, even in the face of errors.</span>
<span id="L236" class="ln">   236  </span>func collectOnce() (RuntimeMetrics, []error) {
<span id="L237" class="ln">   237  </span>	newMetrics := RuntimeMetrics{}
<span id="L238" class="ln">   238  </span>	errs := make([]error, 0)
<span id="L239" class="ln">   239  </span>
<span id="L240" class="ln">   240  </span>	<span class="comment">// We organize the code to collect metrics in the same order that they occur</span>
<span id="L241" class="ln">   241  </span>	<span class="comment">// in the definition of RuntimeMetrics for code organization purposes. Note</span>
<span id="L242" class="ln">   242  </span>	<span class="comment">// that wherever possible, we also populate the returned RuntimeMetrics</span>
<span id="L243" class="ln">   243  </span>	<span class="comment">// struct with invalid data whenever there&#39;s an error collecting a particular</span>
<span id="L244" class="ln">   244  </span>	<span class="comment">// piece of data (e.g. -1 for the recent load). This should make it clear on</span>
<span id="L245" class="ln">   245  </span>	<span class="comment">// a graph, for instance, that our data collection process has run into</span>
<span id="L246" class="ln">   246  </span>	<span class="comment">// errors, and at least prevent us from reaching &#34;sensible&#34; conclusions from</span>
<span id="L247" class="ln">   247  </span>	<span class="comment">// bogus data.</span>
<span id="L248" class="ln">   248  </span>
<span id="L249" class="ln">   249  </span>	<span class="comment">// Memory stats</span>
<span id="L250" class="ln">   250  </span>	if memStats, err := mem.VirtualMemory(); err != nil {
<span id="L251" class="ln">   251  </span>		errs = append(errs, utils.MakeError(&#34;Error getting memory stats: %s&#34;, err))
<span id="L252" class="ln">   252  </span>	} else {
<span id="L253" class="ln">   253  </span>		newMetrics.TotalMemoryKB = memStats.Total / 1024
<span id="L254" class="ln">   254  </span>		newMetrics.FreeMemoryKB = memStats.Free / 1024
<span id="L255" class="ln">   255  </span>		newMetrics.AvailableMemoryKB = memStats.Available / 1024
<span id="L256" class="ln">   256  </span>	}
<span id="L257" class="ln">   257  </span>
<span id="L258" class="ln">   258  </span>	<span class="comment">// CPU stats</span>
<span id="L259" class="ln">   259  </span>	if cpuCount, err := cpu.Counts(true); err != nil {
<span id="L260" class="ln">   260  </span>		errs = append(errs, utils.MakeError(&#34;Error getting Logical CPU count: %s&#34;, err))
<span id="L261" class="ln">   261  </span>	} else {
<span id="L262" class="ln">   262  </span>		newMetrics.LogicalCPUs = cpuCount
<span id="L263" class="ln">   263  </span>
<span id="L264" class="ln">   264  </span>		cpuPercent, err := cpu.Percent(0, false)
<span id="L265" class="ln">   265  </span>		if err != nil {
<span id="L266" class="ln">   266  </span>			errs = append(errs, utils.MakeError(&#34;Error getting CPU utilization: %s&#34;, err))
<span id="L267" class="ln">   267  </span>			newMetrics.CPUUtilizationPercent = -1
<span id="L268" class="ln">   268  </span>		} else {
<span id="L269" class="ln">   269  </span>			newMetrics.CPUUtilizationPercent = cpuPercent[0]
<span id="L270" class="ln">   270  </span>			newMetrics.NanoCPUsRemaining = uint64(cpuCount) * uint64(1e9-1e7*cpuPercent[0])
<span id="L271" class="ln">   271  </span>		}
<span id="L272" class="ln">   272  </span>	}
<span id="L273" class="ln">   273  </span>
<span id="L274" class="ln">   274  </span>	<span class="comment">// GPU stats</span>
<span id="L275" class="ln">   275  </span>	if numGPUs, nvmlRet := nvml.DeviceGetCount(); nvmlRet != nvml.SUCCESS {
<span id="L276" class="ln">   276  </span>		errs = append(errs, utils.MakeError(&#34;Error getting GPU count&#34;))
<span id="L277" class="ln">   277  </span>		newMetrics.NumberOfGPUs = -1
<span id="L278" class="ln">   278  </span>	} else {
<span id="L279" class="ln">   279  </span>		newMetrics.NumberOfGPUs = numGPUs
<span id="L280" class="ln">   280  </span>
<span id="L281" class="ln">   281  </span>		var totalVramKB uint64 = 0
<span id="L282" class="ln">   282  </span>		var usedVramKB uint64 = 0
<span id="L283" class="ln">   283  </span>		var totalKernelUtilPercent uint32 = 0
<span id="L284" class="ln">   284  </span>		var totalMemBandwidthUtilPercent uint32 = 0
<span id="L285" class="ln">   285  </span>		for i := 0; i &lt; numGPUs; i++ {
<span id="L286" class="ln">   286  </span>			if device, nvmlRet := nvml.DeviceGetHandleByIndex(i); nvmlRet != nvml.SUCCESS {
<span id="L287" class="ln">   287  </span>				errs = append(errs, utils.MakeError(&#34;Couldn&#39;t get NVIDIA device at index %v&#34;, i))
<span id="L288" class="ln">   288  </span>				break
<span id="L289" class="ln">   289  </span>			} else {
<span id="L290" class="ln">   290  </span>				if memInfo, nvmlRet := nvml.DeviceGetMemoryInfo(device); nvmlRet != nvml.SUCCESS {
<span id="L291" class="ln">   291  </span>					errs = append(errs, utils.MakeError(&#34;Couldn&#39;t get video memory info for device at NVML index %v&#34;, i))
<span id="L292" class="ln">   292  </span>					break
<span id="L293" class="ln">   293  </span>				} else {
<span id="L294" class="ln">   294  </span>					totalVramKB += memInfo.Total / 1024
<span id="L295" class="ln">   295  </span>					usedVramKB += memInfo.Used / 1024
<span id="L296" class="ln">   296  </span>					<span class="comment">// For some reason, NVML always returns 0 for memInfo.Free, so we do</span>
<span id="L297" class="ln">   297  </span>					<span class="comment">// the free calculation ourselves below.</span>
<span id="L298" class="ln">   298  </span>				}
<span id="L299" class="ln">   299  </span>
<span id="L300" class="ln">   300  </span>				if util, nvmlRet := nvml.DeviceGetUtilizationRates(device); nvmlRet != nvml.SUCCESS {
<span id="L301" class="ln">   301  </span>					errs = append(errs, utils.MakeError(&#34;Couldn&#39;t get utilization info for device at NVML index %v&#34;, i))
<span id="L302" class="ln">   302  </span>					break
<span id="L303" class="ln">   303  </span>				} else {
<span id="L304" class="ln">   304  </span>					totalKernelUtilPercent += util.Gpu
<span id="L305" class="ln">   305  </span>					totalMemBandwidthUtilPercent += util.Memory
<span id="L306" class="ln">   306  </span>				}
<span id="L307" class="ln">   307  </span>			}
<span id="L308" class="ln">   308  </span>		}
<span id="L309" class="ln">   309  </span>
<span id="L310" class="ln">   310  </span>		newMetrics.TotalVideoMemoryKB = totalVramKB
<span id="L311" class="ln">   311  </span>		newMetrics.UsedVideoMemoryKB = usedVramKB
<span id="L312" class="ln">   312  </span>		newMetrics.FreeVideoMemoryKB = totalVramKB - usedVramKB
<span id="L313" class="ln">   313  </span>
<span id="L314" class="ln">   314  </span>		newMetrics.GPUKernelUtilizationPercent = float64(totalKernelUtilPercent) / float64(numGPUs)
<span id="L315" class="ln">   315  </span>		newMetrics.GPUMemoryBandwidthUtilizationPercent = float64(totalMemBandwidthUtilPercent) / float64(numGPUs)
<span id="L316" class="ln">   316  </span>	}
<span id="L317" class="ln">   317  </span>
<span id="L318" class="ln">   318  </span>	<span class="comment">// Load stats</span>
<span id="L319" class="ln">   319  </span>	if avgStat, err := load.Avg(); err != nil {
<span id="L320" class="ln">   320  </span>		errs = append(errs, utils.MakeError(&#34;Couldn&#39;t get average load statistics: %s&#34;, err))
<span id="L321" class="ln">   321  </span>		newMetrics.LoadAverage1Min = -1
<span id="L322" class="ln">   322  </span>		newMetrics.LoadAverage5Min = -1
<span id="L323" class="ln">   323  </span>		newMetrics.LoadAverage15Min = -1
<span id="L324" class="ln">   324  </span>	} else {
<span id="L325" class="ln">   325  </span>		newMetrics.LoadAverage1Min = avgStat.Load1
<span id="L326" class="ln">   326  </span>		newMetrics.LoadAverage5Min = avgStat.Load5
<span id="L327" class="ln">   327  </span>		newMetrics.LoadAverage15Min = avgStat.Load15
<span id="L328" class="ln">   328  </span>	}
<span id="L329" class="ln">   329  </span>
<span id="L330" class="ln">   330  </span>	<span class="comment">// Disk stats</span>
<span id="L331" class="ln">   331  </span>	if diskStat, err := disk.Usage(&#34;/&#34;); err != nil {
<span id="L332" class="ln">   332  </span>		errs = append(errs, utils.MakeError(&#34;Couldn&#39;t get disk usage stats: %s&#34;, err))
<span id="L333" class="ln">   333  </span>		newMetrics.DiskUsedPercent = -1
<span id="L334" class="ln">   334  </span>	} else {
<span id="L335" class="ln">   335  </span>		newMetrics.DiskTotalKB = diskStat.Total / 1024
<span id="L336" class="ln">   336  </span>		newMetrics.DiskUsedKB = diskStat.Used / 1024
<span id="L337" class="ln">   337  </span>		newMetrics.DiskFreeKB = diskStat.Free / 1024
<span id="L338" class="ln">   338  </span>		newMetrics.DiskUsedPercent = diskStat.UsedPercent
<span id="L339" class="ln">   339  </span>	}
<span id="L340" class="ln">   340  </span>
<span id="L341" class="ln">   341  </span>	<span class="comment">// Time stats</span>
<span id="L342" class="ln">   342  </span>	if uptimeSecs, err := host.Uptime(); err != nil {
<span id="L343" class="ln">   343  </span>		errs = append(errs, utils.MakeError(&#34;Couldn&#39;t get uptime for host: %s&#34;, err))
<span id="L344" class="ln">   344  </span>	} else {
<span id="L345" class="ln">   345  </span>		newMetrics.Uptime = time.Second * time.Duration(uptimeSecs)
<span id="L346" class="ln">   346  </span>	}
<span id="L347" class="ln">   347  </span>	newMetrics.TimeStamp = time.Now().UTC()
<span id="L348" class="ln">   348  </span>
<span id="L349" class="ln">   349  </span>	return newMetrics, errs
<span id="L350" class="ln">   350  </span>}
<span id="L351" class="ln">   351  </span>
<span id="L352" class="ln">   352  </span><span class="comment">// GetLatest returns the most recently collected metrics for the host instance,</span>
<span id="L353" class="ln">   353  </span><span class="comment">// as well as any errors encountered while collecting those metrics. All</span>
<span id="L354" class="ln">   354  </span><span class="comment">// metrics are refreshed at approximately the frequency passed into</span>
<span id="L355" class="ln">   355  </span><span class="comment">// StartCollection.</span>
<span id="L356" class="ln">   356  </span>func GetLatest() (RuntimeMetrics, []error) {
<span id="L357" class="ln">   357  </span>	latestLock.Lock()
<span id="L358" class="ln">   358  </span>	defer latestLock.Unlock()
<span id="L359" class="ln">   359  </span>	return latestMetrics, latestErrors
<span id="L360" class="ln">   360  </span>}
<span id="L361" class="ln">   361  </span>
<span id="L362" class="ln">   362  </span><span class="comment">// Close stops the metrics collection goroutine and leaves behind an error for</span>
<span id="L363" class="ln">   363  </span><span class="comment">// anyone who attempts to access the metrics after it is called.</span>
<span id="L364" class="ln">   364  </span>func Close() {
<span id="L365" class="ln">   365  </span>	close(collectionKeepAlive)
<span id="L366" class="ln">   366  </span>
<span id="L367" class="ln">   367  </span>	latestLock.Lock()
<span id="L368" class="ln">   368  </span>	defer latestLock.Unlock()
<span id="L369" class="ln">   369  </span>	latestErrors = []error{
<span id="L370" class="ln">   370  </span>		utils.MakeError(&#34;Metrics-collection goroutine has been stopped.&#34;),
<span id="L371" class="ln">   371  </span>	}
<span id="L372" class="ln">   372  </span>}
<span id="L373" class="ln">   373  </span>
</pre><p></p>

<div id="footer">
Build version go1.17.2.<br/>
</div>

</div><!-- .container -->
</div><!-- #page -->


</body></html>