<!DOCTYPE html><html><head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<meta name="theme-color" content="#375EAB"/>

  <title>src/github.com/whisthq/whist/backend/services/host-service/host-service.go - Whist Backend Services</title>

<link type="text/css" rel="stylesheet" href="https://docs.whist.com/backend/services//lib/godoc/style.css"/>

<script>window.initFuncs = [];</script>
<script src="https://docs.whist.com/backend/services//lib/godoc/jquery.js" defer=""></script>




<script>var goVersion = "go1.18.3";</script>
<script src="https://docs.whist.com/backend/services//lib/godoc/godocs.js" defer=""></script>

</head>
<body>

<div id="lowframe" style="position: fixed; bottom: 0; left: 0; height: 0; width: 100%; border-top: thin solid grey; background-color: white; overflow: auto;">
...
</div><!-- #lowframe -->

<div id="topbar" class="wide"><div class="container">
<div class="top-heading" id="heading-wide"><a href="https:/docs.whist.com/backend/services/pkg/github.com/whisthq/whist/backend/services/">Whist Backend Services | Autogenerated from bea4455</a></div>
<div class="top-heading" id="heading-narrow"><a href="https:/docs.whist.com/backend/services/pkg/github.com/whisthq/whist/backend/services/">Whist Backend Services</a></div>
<a href="#" id="menu-button"><span id="menu-button-arrow">▽</span></a>

</div></div>



<div id="page" class="wide">
<div class="container">


  <h1>
    Source file
    <a href="https:/docs.whist.com/backend/services/src">src</a>/<a href="https:/docs.whist.com/backend/services/src/github.com">github.com</a>/<a href="https:/docs.whist.com/backend/services/src/github.com/whisthq">whisthq</a>/<a href="https:/docs.whist.com/backend/services/src/github.com/whisthq/whist">whist</a>/<a href="https:/docs.whist.com/backend/services/src/github.com/whisthq/whist/backend">backend</a>/<a href="https:/docs.whist.com/backend/services/src/github.com/whisthq/whist/backend/services">services</a>/<a href="https:/docs.whist.com/backend/services/src/github.com/whisthq/whist/backend/services/host-service">host-service</a>/<span class="text-muted">host-service.go</span>
  </h1>





  <h2>
    Documentation: <a href="https:/docs.whist.com/backend/services/pkg/github.com/whisthq/whist/backend/services/host-service">github.com/whisthq/whist/backend/services/host-service</a>
  </h2>



<div id="nav"></div>


<script type="text/javascript">document.ANALYSIS_DATA = null;</script>
<pre><span id="L1" class="ln">     1  </span><span class="comment">/*
<span id="L2" class="ln">     2  </span>The Whist Host-Service is responsible for orchestrating mandelboxes (i.e.
<span id="L3" class="ln">     3  </span>Whist-enabled containers) on EC2 instances (referred to as &#34;hosts&#34; throughout
<span id="L4" class="ln">     4  </span>the codebase). The host-service is responsible for making Docker calls to start
<span id="L5" class="ln">     5  </span>and stop mandelboxes, for enabling multiple mandelboxes to run concurrently on
<span id="L6" class="ln">     6  </span>the same host (by dynamically allocating and assigning resources), and for
<span id="L7" class="ln">     7  </span>passing startup data to the mandelboxes, both from the rest of the backend and
<span id="L8" class="ln">     8  </span>from the user&#39;s frontend application.
<span id="L9" class="ln">     9  </span>
<span id="L10" class="ln">    10  </span>If you are just interested in seeing what endpoints the host-service exposes
<span id="L11" class="ln">    11  </span>(i.e. for frontend development), check out the file `httpserver.go`.
<span id="L12" class="ln">    12  </span>
<span id="L13" class="ln">    13  </span>The main package of the host service contains the main logic and the most
<span id="L14" class="ln">    14  </span>comments to explain the design decisions of the host service. It also contains
<span id="L15" class="ln">    15  </span>an HTTPS server that exposes the necessary endpoints and sets up the necessary
<span id="L16" class="ln">    16  </span>infrastructure for concurrent handlers, etc.
<span id="L17" class="ln">    17  </span>*/</span>
<span id="L18" class="ln">    18  </span>package main
<span id="L19" class="ln">    19  </span>
<span id="L20" class="ln">    20  </span>import (
<span id="L21" class="ln">    21  </span>	<span class="comment">// NOTE: The &#34;fmt&#34; or &#34;log&#34; packages should never be imported!!! This is so</span>
<span id="L22" class="ln">    22  </span>	<span class="comment">// that we never forget to send a message via Sentry. Instead, use the</span>
<span id="L23" class="ln">    23  </span>	<span class="comment">// whistlogger package imported below as `logger`.</span>
<span id="L24" class="ln">    24  </span>
<span id="L25" class="ln">    25  </span>	&#34;context&#34;
<span id="L26" class="ln">    26  </span>	_ &#34;embed&#34;
<span id="L27" class="ln">    27  </span>	&#34;io&#34;
<span id="L28" class="ln">    28  </span>	&#34;math/rand&#34;
<span id="L29" class="ln">    29  </span>	&#34;os&#34;
<span id="L30" class="ln">    30  </span>	&#34;os/exec&#34;
<span id="L31" class="ln">    31  </span>	&#34;os/signal&#34;
<span id="L32" class="ln">    32  </span>	&#34;path&#34;
<span id="L33" class="ln">    33  </span>	&#34;regexp&#34;
<span id="L34" class="ln">    34  </span>	&#34;strings&#34;
<span id="L35" class="ln">    35  </span>	&#34;sync&#34;
<span id="L36" class="ln">    36  </span>	&#34;syscall&#34;
<span id="L37" class="ln">    37  </span>	&#34;time&#34;
<span id="L38" class="ln">    38  </span>
<span id="L39" class="ln">    39  </span>	<span class="comment">// We use this package instead of the standard library log so that we never</span>
<span id="L40" class="ln">    40  </span>	<span class="comment">// forget to send a message via Sentry. For the same reason, we make sure not</span>
<span id="L41" class="ln">    41  </span>	<span class="comment">// to import the fmt package either, instead separating required</span>
<span id="L42" class="ln">    42  </span>	<span class="comment">// functionality in this imported package as well.</span>
<span id="L43" class="ln">    43  </span>
<span id="L44" class="ln">    44  </span>	&#34;github.com/google/uuid&#34;
<span id="L45" class="ln">    45  </span>	&#34;github.com/whisthq/whist/backend/services/httputils&#34;
<span id="L46" class="ln">    46  </span>	logger &#34;github.com/whisthq/whist/backend/services/whistlogger&#34;
<span id="L47" class="ln">    47  </span>
<span id="L48" class="ln">    48  </span>	&#34;github.com/whisthq/whist/backend/services/host-service/dbdriver&#34;
<span id="L49" class="ln">    49  </span>	mandelboxData &#34;github.com/whisthq/whist/backend/services/host-service/mandelbox&#34;
<span id="L50" class="ln">    50  </span>	&#34;github.com/whisthq/whist/backend/services/host-service/metrics&#34;
<span id="L51" class="ln">    51  </span>	&#34;github.com/whisthq/whist/backend/services/metadata&#34;
<span id="L52" class="ln">    52  </span>	&#34;github.com/whisthq/whist/backend/services/metadata/aws&#34;
<span id="L53" class="ln">    53  </span>	&#34;github.com/whisthq/whist/backend/services/subscriptions&#34;
<span id="L54" class="ln">    54  </span>	mandelboxtypes &#34;github.com/whisthq/whist/backend/services/types&#34;
<span id="L55" class="ln">    55  </span>	&#34;github.com/whisthq/whist/backend/services/utils&#34;
<span id="L56" class="ln">    56  </span>
<span id="L57" class="ln">    57  </span>	dockertypes &#34;github.com/docker/docker/api/types&#34;
<span id="L58" class="ln">    58  </span>	dockerevents &#34;github.com/docker/docker/api/types/events&#34;
<span id="L59" class="ln">    59  </span>	dockerfilters &#34;github.com/docker/docker/api/types/filters&#34;
<span id="L60" class="ln">    60  </span>	dockerclient &#34;github.com/docker/docker/client&#34;
<span id="L61" class="ln">    61  </span>)
<span id="L62" class="ln">    62  </span>
<span id="L63" class="ln">    63  </span>var shutdownInstanceOnExit bool = !metadata.IsLocalEnv()
<span id="L64" class="ln">    64  </span>
<span id="L65" class="ln">    65  </span>func init() {
<span id="L66" class="ln">    66  </span>	<span class="comment">// Initialize random number generator for all subpackages</span>
<span id="L67" class="ln">    67  </span>	rand.Seed(time.Now().UnixNano())
<span id="L68" class="ln">    68  </span>
<span id="L69" class="ln">    69  </span>	<span class="comment">// Check that the program has been started with the correct permissions ---</span>
<span id="L70" class="ln">    70  </span>	<span class="comment">// for now, we just want to run as root, but this service could be assigned</span>
<span id="L71" class="ln">    71  </span>	<span class="comment">// its own user in the future.</span>
<span id="L72" class="ln">    72  </span>	if os.Geteuid() != 0 {
<span id="L73" class="ln">    73  </span>		<span class="comment">// We can do a &#34;real&#34; panic here because it&#39;s in an init function, so we</span>
<span id="L74" class="ln">    74  </span>		<span class="comment">// haven&#39;t even entered the host-service main() yet.</span>
<span id="L75" class="ln">    75  </span>		logger.Panicf(nil, &#34;This service needs to run as root!&#34;)
<span id="L76" class="ln">    76  </span>	}
<span id="L77" class="ln">    77  </span>}
<span id="L78" class="ln">    78  </span>
<span id="L79" class="ln">    79  </span><span class="comment">// createDockerClient creates a docker client. It returns an error if creation</span>
<span id="L80" class="ln">    80  </span><span class="comment">// failed.</span>
<span id="L81" class="ln">    81  </span>func createDockerClient() (*dockerclient.Client, error) {
<span id="L82" class="ln">    82  </span>	client, err := dockerclient.NewClientWithOpts(dockerclient.WithAPIVersionNegotiation())
<span id="L83" class="ln">    83  </span>	if err != nil {
<span id="L84" class="ln">    84  </span>		return nil, utils.MakeError(&#34;Error creating new Docker client: %s&#34;, err)
<span id="L85" class="ln">    85  </span>	}
<span id="L86" class="ln">    86  </span>	return client, nil
<span id="L87" class="ln">    87  </span>}
<span id="L88" class="ln">    88  </span>
<span id="L89" class="ln">    89  </span><span class="comment">// Given a list of regexes, find a Docker image whose name matches the earliest</span>
<span id="L90" class="ln">    90  </span><span class="comment">// possible regex in the list.</span>
<span id="L91" class="ln">    91  </span>func dockerImageFromRegexes(globalCtx context.Context, dockerClient dockerclient.CommonAPIClient, regexes []string) string {
<span id="L92" class="ln">    92  </span>	imageFilters := dockerfilters.NewArgs(
<span id="L93" class="ln">    93  </span>		dockerfilters.KeyValuePair{Key: &#34;dangling&#34;, Value: &#34;false&#34;},
<span id="L94" class="ln">    94  </span>	)
<span id="L95" class="ln">    95  </span>	images, err := dockerClient.ImageList(globalCtx, dockertypes.ImageListOptions{All: false, Filters: imageFilters})
<span id="L96" class="ln">    96  </span>	if err != nil {
<span id="L97" class="ln">    97  </span>		return &#34;&#34;
<span id="L98" class="ln">    98  </span>	}
<span id="L99" class="ln">    99  </span>
<span id="L100" class="ln">   100  </span>	for _, regex := range regexes {
<span id="L101" class="ln">   101  </span>		rgx := regexp.MustCompile(regex)
<span id="L102" class="ln">   102  </span>		for _, img := range images {
<span id="L103" class="ln">   103  </span>			for _, tag := range img.RepoTags {
<span id="L104" class="ln">   104  </span>				if rgx.MatchString(tag) {
<span id="L105" class="ln">   105  </span>					return tag
<span id="L106" class="ln">   106  </span>				}
<span id="L107" class="ln">   107  </span>			}
<span id="L108" class="ln">   108  </span>		}
<span id="L109" class="ln">   109  </span>	}
<span id="L110" class="ln">   110  </span>	return &#34;&#34;
<span id="L111" class="ln">   111  </span>}
<span id="L112" class="ln">   112  </span>
<span id="L113" class="ln">   113  </span><span class="comment">// Drain and shutdown the host-service</span>
<span id="L114" class="ln">   114  </span>func drainAndShutdown(globalCtx context.Context, globalCancel context.CancelFunc, goroutineTracker *sync.WaitGroup) {
<span id="L115" class="ln">   115  </span>	logger.Infof(&#34;Got a DrainAndShutdownRequest... cancelling the global context.&#34;)
<span id="L116" class="ln">   116  </span>	shutdownInstanceOnExit = true
<span id="L117" class="ln">   117  </span>	globalCancel()
<span id="L118" class="ln">   118  </span>}
<span id="L119" class="ln">   119  </span>
<span id="L120" class="ln">   120  </span>func SpinUpMandelboxes(globalCtx context.Context, globalCancel context.CancelFunc, goroutineTracker *sync.WaitGroup, dockerClient dockerclient.CommonAPIClient, instanceID string, instanceCapacity int32) {
<span id="L121" class="ln">   121  </span>	if metadata.IsLocalEnvWithoutDB() &amp;&amp; !metadata.IsRunningInCI() {
<span id="L122" class="ln">   122  </span>		return
<span id="L123" class="ln">   123  </span>	}
<span id="L124" class="ln">   124  </span>
<span id="L125" class="ln">   125  </span>	<span class="comment">// Start all waiting mandelboxes we can (i.e. as many as we have capacity for) and register to database</span>
<span id="L126" class="ln">   126  </span>	<span class="comment">// with the &#34;WAITING&#34; status. The instance capacity is determined by the scaling service for each instance type.</span>
<span id="L127" class="ln">   127  </span>	for i := int32(0); i &lt; instanceCapacity; i++ {
<span id="L128" class="ln">   128  </span>		mandelboxID := mandelboxtypes.MandelboxID(uuid.New())
<span id="L129" class="ln">   129  </span>		<span class="comment">// Replace &#34;chrome&#34; by &#34;brave&#34; (or some other container we support) to test a different app. Note that the Whist</span>
<span id="L130" class="ln">   130  </span>		<span class="comment">// backend is designed to only ever deploy the same application everywhere, which we hardcode here.</span>
<span id="L131" class="ln">   131  </span>		var appName mandelboxtypes.AppName = &#34;browsers/chrome&#34;
<span id="L132" class="ln">   132  </span>		zygote := StartMandelboxSpinUp(globalCtx, globalCancel, goroutineTracker, dockerClient, mandelboxID, appName)
<span id="L133" class="ln">   133  </span>
<span id="L134" class="ln">   134  </span>		<span class="comment">// If we fail to create a zygote mandelbox, it indicates a problem with the instance, or the Docker</span>
<span id="L135" class="ln">   135  </span>		<span class="comment">// images. Its not safe to assign users to it, so we cancel the global context and shut down the instance</span>
<span id="L136" class="ln">   136  </span>		if zygote == nil {
<span id="L137" class="ln">   137  </span>			globalCancel()
<span id="L138" class="ln">   138  </span>			return
<span id="L139" class="ln">   139  </span>		}
<span id="L140" class="ln">   140  </span>
<span id="L141" class="ln">   141  </span>		<span class="comment">// We have to parse the appname before writing to the database.</span>
<span id="L142" class="ln">   142  </span>		appString := strings.Split(string(zygote.GetAppName()), &#34;/&#34;)
<span id="L143" class="ln">   143  </span>		appNameForDb := strings.ToUpper(appString[1])
<span id="L144" class="ln">   144  </span>		err := dbdriver.CreateMandelbox(zygote.GetID(), appNameForDb, instanceID)
<span id="L145" class="ln">   145  </span>		if err != nil {
<span id="L146" class="ln">   146  </span>			logger.Errorf(&#34;Failed to register mandelbox %v on database. Err: %v&#34;, zygote.GetID(), err)
<span id="L147" class="ln">   147  </span>		}
<span id="L148" class="ln">   148  </span>	}
<span id="L149" class="ln">   149  </span>}
<span id="L150" class="ln">   150  </span>
<span id="L151" class="ln">   151  </span><span class="comment">// Handle tasks to be completed when a mandelbox dies</span>
<span id="L152" class="ln">   152  </span>func mandelboxDieHandler(id string, transportRequestMap map[mandelboxtypes.MandelboxID]chan *httputils.JSONTransportRequest, transportMapLock *sync.Mutex, dockerClient dockerclient.CommonAPIClient) {
<span id="L153" class="ln">   153  </span>	<span class="comment">// Exit if we are not dealing with a Whist mandelbox, or if it has already</span>
<span id="L154" class="ln">   154  </span>	<span class="comment">// been closed (via a call to Close() or a context cancellation).</span>
<span id="L155" class="ln">   155  </span>	mandelbox, err := mandelboxData.LookUpByDockerID(mandelboxtypes.DockerID(id))
<span id="L156" class="ln">   156  </span>	if err != nil {
<span id="L157" class="ln">   157  </span>		logger.Infof(&#34;mandelboxDieHandler(): %s&#34;, err)
<span id="L158" class="ln">   158  </span>		return
<span id="L159" class="ln">   159  </span>	}
<span id="L160" class="ln">   160  </span>
<span id="L161" class="ln">   161  </span>	<span class="comment">// Clean up this user from the JSON transport request map.</span>
<span id="L162" class="ln">   162  </span>	mandelboxID := mandelbox.GetID()
<span id="L163" class="ln">   163  </span>	transportMapLock.Lock()
<span id="L164" class="ln">   164  </span>	transportRequestMap[mandelboxID] = nil
<span id="L165" class="ln">   165  </span>	transportMapLock.Unlock()
<span id="L166" class="ln">   166  </span>
<span id="L167" class="ln">   167  </span>	<span class="comment">// Gracefully shut down the mandelbox Docker container</span>
<span id="L168" class="ln">   168  </span>	stopTimeout := 15 * time.Second
<span id="L169" class="ln">   169  </span>	stopCtx, cancel := context.WithCancel(context.Background())
<span id="L170" class="ln">   170  </span>	defer cancel()
<span id="L171" class="ln">   171  </span>
<span id="L172" class="ln">   172  </span>	err = dockerClient.ContainerStop(stopCtx, id, &amp;stopTimeout)
<span id="L173" class="ln">   173  </span>	if err != nil {
<span id="L174" class="ln">   174  </span>		logger.Errorf(&#34;Failed to gracefully stop mandelbox docker container. Err: %v&#34;, err)
<span id="L175" class="ln">   175  </span>		metrics.Increment(&#34;ErrorRate&#34;)
<span id="L176" class="ln">   176  </span>	}
<span id="L177" class="ln">   177  </span>
<span id="L178" class="ln">   178  </span>	logger.Infof(&#34;Successfully stopped docker container, cancelling mandelbox context.&#34;)
<span id="L179" class="ln">   179  </span>	mandelbox.Close()
<span id="L180" class="ln">   180  </span>}
<span id="L181" class="ln">   181  </span>
<span id="L182" class="ln">   182  </span><span class="comment">// ---------------------------</span>
<span id="L183" class="ln">   183  </span><span class="comment">// Service shutdown and initialization</span>
<span id="L184" class="ln">   184  </span><span class="comment">// ---------------------------</span>
<span id="L185" class="ln">   185  </span>
<span id="L186" class="ln">   186  </span><span class="comment">//go:embed mandelbox-apparmor-profile</span>
<span id="L187" class="ln">   187  </span>var appArmorProfile string
<span id="L188" class="ln">   188  </span>
<span id="L189" class="ln">   189  </span><span class="comment">// Create and register the AppArmor profile for Docker to use with</span>
<span id="L190" class="ln">   190  </span><span class="comment">// mandelboxes. These do not persist, so must be done at service</span>
<span id="L191" class="ln">   191  </span><span class="comment">// startup.</span>
<span id="L192" class="ln">   192  </span>func initializeAppArmor(globalCancel context.CancelFunc) {
<span id="L193" class="ln">   193  </span>	cmd := exec.Command(&#34;apparmor_parser&#34;, &#34;-Kr&#34;)
<span id="L194" class="ln">   194  </span>	stdin, err := cmd.StdinPipe()
<span id="L195" class="ln">   195  </span>	if err != nil {
<span id="L196" class="ln">   196  </span>		logger.Panicf(globalCancel, &#34;Unable to attach to process &#39;stdin&#39; pipe. Error: %v&#34;, err)
<span id="L197" class="ln">   197  </span>	}
<span id="L198" class="ln">   198  </span>
<span id="L199" class="ln">   199  </span>	go func() {
<span id="L200" class="ln">   200  </span>		defer stdin.Close()
<span id="L201" class="ln">   201  </span>		io.WriteString(stdin, appArmorProfile)
<span id="L202" class="ln">   202  </span>	}()
<span id="L203" class="ln">   203  </span>
<span id="L204" class="ln">   204  </span>	err = cmd.Run()
<span id="L205" class="ln">   205  </span>	if err != nil {
<span id="L206" class="ln">   206  </span>		logger.Panicf(globalCancel, &#34;Unable to register AppArmor profile. Error: %v&#34;, err)
<span id="L207" class="ln">   207  </span>	}
<span id="L208" class="ln">   208  </span>}
<span id="L209" class="ln">   209  </span>
<span id="L210" class="ln">   210  </span><span class="comment">// Create the directory used to store the mandelbox resource allocations</span>
<span id="L211" class="ln">   211  </span><span class="comment">// (e.g. TTYs) on disk</span>
<span id="L212" class="ln">   212  </span>func initializeFilesystem(globalCancel context.CancelFunc) {
<span id="L213" class="ln">   213  </span>	<span class="comment">// Check if the instance has ephemeral storage. If it does, set the WhistDir path to the</span>
<span id="L214" class="ln">   214  </span>	<span class="comment">// ephemeral volume, which should already be mounted by the userdata script. We use the</span>
<span id="L215" class="ln">   215  </span>	<span class="comment">// command below to check if the instance has an ephemeral device present.</span>
<span id="L216" class="ln">   216  </span>	<span class="comment">// See: https://stackoverflow.com/questions/10781516/how-to-pipe-several-commands-in-go</span>
<span id="L217" class="ln">   217  </span>	ephemeralDeviceCmd := &#34;nvme list -o json | jq -r &#39;.Devices | map(select(.ModelNumber == \&#34;Amazon EC2 NVMe Instance Storage\&#34;)) | max_by(.PhysicalSize) | .DevicePath&#39;&#34;
<span id="L218" class="ln">   218  </span>	out, err := exec.Command(&#34;bash&#34;, &#34;-c&#34;, ephemeralDeviceCmd).CombinedOutput()
<span id="L219" class="ln">   219  </span>	if err != nil {
<span id="L220" class="ln">   220  </span>		logger.Errorf(&#34;Error while getting ephemeral device path, not using ephemeral storage.&#34;)
<span id="L221" class="ln">   221  </span>	}
<span id="L222" class="ln">   222  </span>
<span id="L223" class="ln">   223  </span>	ephemeralDevicePath := string(out)
<span id="L224" class="ln">   224  </span>
<span id="L225" class="ln">   225  </span>	<span class="comment">// We check if the command exited successfully, and if the ephemeral device exists.</span>
<span id="L226" class="ln">   226  </span>	<span class="comment">// The string will contain &#34;bash&#34; if something went wrong. Also take into account</span>
<span id="L227" class="ln">   227  </span>	<span class="comment">// if the WhistDir already contains the ephemeral path.</span>
<span id="L228" class="ln">   228  </span>	if !metadata.IsLocalEnv() &amp;&amp;
<span id="L229" class="ln">   229  </span>		ephemeralDevicePath != &#34;&#34; &amp;&amp; ephemeralDevicePath != &#34;null&#34; &amp;&amp;
<span id="L230" class="ln">   230  </span>		!strings.Contains(ephemeralDevicePath, &#34;bash&#34;) &amp;&amp; !strings.Contains(utils.WhistDir, utils.WhistEphemeralFSPath) {
<span id="L231" class="ln">   231  </span>		logger.Infof(&#34;Creating Whist directory on ephemeral device.&#34;)
<span id="L232" class="ln">   232  </span>		utils.WhistDir = path.Join(utils.WhistEphemeralFSPath, utils.WhistDir)
<span id="L233" class="ln">   233  </span>		utils.TempDir = path.Join(utils.WhistDir, &#34;temp/&#34;)
<span id="L234" class="ln">   234  </span>	}
<span id="L235" class="ln">   235  </span>
<span id="L236" class="ln">   236  </span>	<span class="comment">// check if &#34;/whist&#34; already exists --- if so, panic, since</span>
<span id="L237" class="ln">   237  </span>	<span class="comment">// we don&#39;t know why it&#39;s there or if it&#39;s valid. The host-service shutting down</span>
<span id="L238" class="ln">   238  </span>	<span class="comment">// from this panic will clean up the directory and the next run will work properly.</span>
<span id="L239" class="ln">   239  </span>	if _, err := os.Lstat(utils.WhistDir); !os.IsNotExist(err) {
<span id="L240" class="ln">   240  </span>		if err == nil {
<span id="L241" class="ln">   241  </span>			logger.Panicf(globalCancel, &#34;Directory %s already exists!&#34;, utils.WhistDir)
<span id="L242" class="ln">   242  </span>		} else {
<span id="L243" class="ln">   243  </span>			logger.Panicf(globalCancel, &#34;Could not make directory %s because of error %v&#34;, utils.WhistDir, err)
<span id="L244" class="ln">   244  </span>		}
<span id="L245" class="ln">   245  </span>	}
<span id="L246" class="ln">   246  </span>
<span id="L247" class="ln">   247  </span>	<span class="comment">// Create the whist directory and make it non-root user owned so that</span>
<span id="L248" class="ln">   248  </span>	<span class="comment">// non-root users in mandelboxes can access files within (especially user</span>
<span id="L249" class="ln">   249  </span>	<span class="comment">// configs).</span>
<span id="L250" class="ln">   250  </span>	err = os.MkdirAll(utils.WhistDir, 0777)
<span id="L251" class="ln">   251  </span>	if err != nil {
<span id="L252" class="ln">   252  </span>		logger.Panicf(globalCancel, &#34;Failed to create directory %s: error: %s\n&#34;, utils.WhistDir, err)
<span id="L253" class="ln">   253  </span>	}
<span id="L254" class="ln">   254  </span>	cmd := exec.Command(&#34;chown&#34;, &#34;-R&#34;, &#34;ubuntu&#34;, utils.WhistDir)
<span id="L255" class="ln">   255  </span>	cmd.Run()
<span id="L256" class="ln">   256  </span>
<span id="L257" class="ln">   257  </span>	<span class="comment">// Create whist-private directory</span>
<span id="L258" class="ln">   258  </span>	err = os.MkdirAll(utils.WhistPrivateDir, 0777)
<span id="L259" class="ln">   259  </span>	if err != nil {
<span id="L260" class="ln">   260  </span>		logger.Panicf(globalCancel, &#34;Failed to create directory %s: error: %s\n&#34;, utils.WhistPrivateDir, err)
<span id="L261" class="ln">   261  </span>	}
<span id="L262" class="ln">   262  </span>
<span id="L263" class="ln">   263  </span>	<span class="comment">// Create whist temp directory (only let root read and write this, since it</span>
<span id="L264" class="ln">   264  </span>	<span class="comment">// contains logs and uinput sockets).</span>
<span id="L265" class="ln">   265  </span>	err = os.MkdirAll(utils.TempDir, 0600)
<span id="L266" class="ln">   266  </span>	if err != nil {
<span id="L267" class="ln">   267  </span>		logger.Panicf(globalCancel, &#34;Could not mkdir path %s. Error: %s&#34;, utils.TempDir, err)
<span id="L268" class="ln">   268  </span>	}
<span id="L269" class="ln">   269  </span>}
<span id="L270" class="ln">   270  </span>
<span id="L271" class="ln">   271  </span><span class="comment">// Delete the directory used to store the mandelbox resource allocations (e.g.</span>
<span id="L272" class="ln">   272  </span><span class="comment">// TTYs) on disk, as well as the directory used to store the SSL certificate we</span>
<span id="L273" class="ln">   273  </span><span class="comment">// use for the httpserver, and our temporary directory.</span>
<span id="L274" class="ln">   274  </span>func uninitializeFilesystem() {
<span id="L275" class="ln">   275  </span>	logger.Infof(&#34;removing all files&#34;)
<span id="L276" class="ln">   276  </span>	err := os.RemoveAll(utils.WhistDir)
<span id="L277" class="ln">   277  </span>	if err != nil {
<span id="L278" class="ln">   278  </span>		logger.Errorf(&#34;Failed to delete directory %s: error: %v\n&#34;, utils.WhistDir, err)
<span id="L279" class="ln">   279  </span>		metrics.Increment(&#34;ErrorRate&#34;)
<span id="L280" class="ln">   280  </span>	} else {
<span id="L281" class="ln">   281  </span>		logger.Infof(&#34;Successfully deleted directory %s\n&#34;, utils.WhistDir)
<span id="L282" class="ln">   282  </span>	}
<span id="L283" class="ln">   283  </span>
<span id="L284" class="ln">   284  </span>	err = os.RemoveAll(utils.WhistPrivateDir)
<span id="L285" class="ln">   285  </span>	if err != nil {
<span id="L286" class="ln">   286  </span>		logger.Errorf(&#34;Failed to delete directory %s: error: %v\n&#34;, utils.WhistPrivateDir, err)
<span id="L287" class="ln">   287  </span>		metrics.Increment(&#34;ErrorRate&#34;)
<span id="L288" class="ln">   288  </span>	} else {
<span id="L289" class="ln">   289  </span>		logger.Infof(&#34;Successfully deleted directory %s\n&#34;, utils.WhistPrivateDir)
<span id="L290" class="ln">   290  </span>	}
<span id="L291" class="ln">   291  </span>
<span id="L292" class="ln">   292  </span>	err = os.RemoveAll(utils.TempDir)
<span id="L293" class="ln">   293  </span>	if err != nil {
<span id="L294" class="ln">   294  </span>		logger.Errorf(&#34;Failed to delete directory %s: error: %v\n&#34;, utils.TempDir, err)
<span id="L295" class="ln">   295  </span>		metrics.Increment(&#34;ErrorRate&#34;)
<span id="L296" class="ln">   296  </span>	} else {
<span id="L297" class="ln">   297  </span>		logger.Infof(&#34;Successfully deleted directory %s\n&#34;, utils.TempDir)
<span id="L298" class="ln">   298  </span>	}
<span id="L299" class="ln">   299  </span>}
<span id="L300" class="ln">   300  </span>
<span id="L301" class="ln">   301  </span>func main() {
<span id="L302" class="ln">   302  </span>	<span class="comment">// Set Sentry tags</span>
<span id="L303" class="ln">   303  </span>	tags, err := aws.GetAWSMetadata()
<span id="L304" class="ln">   304  </span>	if err != nil {
<span id="L305" class="ln">   305  </span>		logger.Errorf(&#34;Failed to set Sentry tags: %s&#34;, err)
<span id="L306" class="ln">   306  </span>	}
<span id="L307" class="ln">   307  </span>	logger.AddSentryTags(tags)
<span id="L308" class="ln">   308  </span>
<span id="L309" class="ln">   309  </span>	<span class="comment">// Add some additional fields for Logz.io</span>
<span id="L310" class="ln">   310  </span>	tags[&#34;component&#34;] = &#34;backend&#34;
<span id="L311" class="ln">   311  </span>	tags[&#34;sub-component&#34;] = &#34;host-service&#34;
<span id="L312" class="ln">   312  </span>	logger.AddLogzioFields(tags)
<span id="L313" class="ln">   313  </span>
<span id="L314" class="ln">   314  </span>	<span class="comment">// We create a global context (i.e. for the entire host service) that can be</span>
<span id="L315" class="ln">   315  </span>	<span class="comment">// cancelled if the entire program needs to terminate. We also create a</span>
<span id="L316" class="ln">   316  </span>	<span class="comment">// WaitGroup for all goroutines to tell us when they&#39;ve stopped (if the</span>
<span id="L317" class="ln">   317  </span>	<span class="comment">// context gets cancelled). Finally, we defer a function which cancels the</span>
<span id="L318" class="ln">   318  </span>	<span class="comment">// global context if necessary, logs any panic we might be recovering from,</span>
<span id="L319" class="ln">   319  </span>	<span class="comment">// and cleans up after the entire host service (although some aspects of</span>
<span id="L320" class="ln">   320  </span>	<span class="comment">// cleanup may not seem necessary on a production instance, they are</span>
<span id="L321" class="ln">   321  </span>	<span class="comment">// immensely helpful to prevent the host service from clogging up the local</span>
<span id="L322" class="ln">   322  </span>	<span class="comment">// filesystem during development). After the permissions check, the creation</span>
<span id="L323" class="ln">   323  </span>	<span class="comment">// of this context and WaitGroup, and the following defer must be the first</span>
<span id="L324" class="ln">   324  </span>	<span class="comment">// statements in main().</span>
<span id="L325" class="ln">   325  </span>	globalCtx, globalCancel := context.WithCancel(context.Background())
<span id="L326" class="ln">   326  </span>	goroutineTracker := sync.WaitGroup{}
<span id="L327" class="ln">   327  </span>
<span id="L328" class="ln">   328  </span>	<span class="comment">// Start Docker</span>
<span id="L329" class="ln">   329  </span>	dockerClient, err := createDockerClient()
<span id="L330" class="ln">   330  </span>	if err != nil {
<span id="L331" class="ln">   331  </span>		logger.Panic(globalCancel, err)
<span id="L332" class="ln">   332  </span>	}
<span id="L333" class="ln">   333  </span>
<span id="L334" class="ln">   334  </span>	defer func() {
<span id="L335" class="ln">   335  </span>		<span class="comment">// This function cleanly shuts down the Whist Host-Service. Note that</span>
<span id="L336" class="ln">   336  </span>		<span class="comment">// besides the host machine itself being forcefully shut down, this</span>
<span id="L337" class="ln">   337  </span>		<span class="comment">// deferred function from main() should be the _only_ way that the host</span>
<span id="L338" class="ln">   338  </span>		<span class="comment">// service exits. In particular, it should be as a result of a panic() in</span>
<span id="L339" class="ln">   339  </span>		<span class="comment">// main, the global context being cancelled, or a Ctrl+C interrupt.</span>
<span id="L340" class="ln">   340  </span>
<span id="L341" class="ln">   341  </span>		<span class="comment">// Note that this function, while nontrivial, has intentionally been left</span>
<span id="L342" class="ln">   342  </span>		<span class="comment">// as part of main() for the following reasons:</span>
<span id="L343" class="ln">   343  </span>		<span class="comment">//   1. To prevent it being called from anywhere else accidentally</span>
<span id="L344" class="ln">   344  </span>		<span class="comment">//   2. To keep the entire program control flow clearly in main().</span>
<span id="L345" class="ln">   345  </span>
<span id="L346" class="ln">   346  </span>		<span class="comment">// Catch any panics that might have originated in main() or one of its</span>
<span id="L347" class="ln">   347  </span>		<span class="comment">// direct children.</span>
<span id="L348" class="ln">   348  </span>		r := recover()
<span id="L349" class="ln">   349  </span>		if r != nil {
<span id="L350" class="ln">   350  </span>			logger.Infof(&#34;Shutting down host service after caught panic in main(): %v&#34;, r)
<span id="L351" class="ln">   351  </span>		} else {
<span id="L352" class="ln">   352  </span>			logger.Infof(&#34;Beginning host service shutdown procedure...&#34;)
<span id="L353" class="ln">   353  </span>		}
<span id="L354" class="ln">   354  </span>
<span id="L355" class="ln">   355  </span>		<span class="comment">// Cancel the global context, if it hasn&#39;t already been cancelled.</span>
<span id="L356" class="ln">   356  </span>		globalCancel()
<span id="L357" class="ln">   357  </span>
<span id="L358" class="ln">   358  </span>		<span class="comment">// Clean all the waiting mandelboxes so they don&#39;t block the shut down.</span>
<span id="L359" class="ln">   359  </span>		<span class="comment">// when this function exits. Stop after we cancel the global context so</span>
<span id="L360" class="ln">   360  </span>		<span class="comment">// that subscriptions are stopped and we don&#39;t trigger any database event.</span>
<span id="L361" class="ln">   361  </span>		mandelboxData.StopWaitingMandelboxes(dockerClient)
<span id="L362" class="ln">   362  </span>
<span id="L363" class="ln">   363  </span>		<span class="comment">// Wait for all goroutines to stop, so we can run the rest of the cleanup</span>
<span id="L364" class="ln">   364  </span>		<span class="comment">// process.</span>
<span id="L365" class="ln">   365  </span>		utils.WaitWithDebugPrints(&amp;goroutineTracker, 2*time.Minute, 2)
<span id="L366" class="ln">   366  </span>
<span id="L367" class="ln">   367  </span>		<span class="comment">// Stop processing new events</span>
<span id="L368" class="ln">   368  </span>		close(eventLoopKeepalive)
<span id="L369" class="ln">   369  </span>
<span id="L370" class="ln">   370  </span>		uninitializeFilesystem()
<span id="L371" class="ln">   371  </span>
<span id="L372" class="ln">   372  </span>		<span class="comment">// Remove our row from the database and close out the database driver.</span>
<span id="L373" class="ln">   373  </span>		dbdriver.Close()
<span id="L374" class="ln">   374  </span>
<span id="L375" class="ln">   375  </span>		<span class="comment">// Close out our metrics collection.</span>
<span id="L376" class="ln">   376  </span>		metrics.Close()
<span id="L377" class="ln">   377  </span>
<span id="L378" class="ln">   378  </span>		<span class="comment">// Drain to our remote logging providers, but don&#39;t yet stop recording new</span>
<span id="L379" class="ln">   379  </span>		<span class="comment">// events, in case the shutdown fails.</span>
<span id="L380" class="ln">   380  </span>		logger.Sync()
<span id="L381" class="ln">   381  </span>
<span id="L382" class="ln">   382  </span>		logger.Info(&#34;Finished host service shutdown procedure. Finally exiting...&#34;)
<span id="L383" class="ln">   383  </span>		if shutdownInstanceOnExit {
<span id="L384" class="ln">   384  </span>			if err := exec.Command(&#34;shutdown&#34;, &#34;now&#34;).Run(); err != nil {
<span id="L385" class="ln">   385  </span>				if strings.TrimSpace(err.Error()) == &#34;signal: terminated&#34; {
<span id="L386" class="ln">   386  </span>					<span class="comment">// The instance seems to shut down even when this error is fired, so</span>
<span id="L387" class="ln">   387  </span>					<span class="comment">// we&#39;ll just ignore it. We still `logger.Info()` it just in case.</span>
<span id="L388" class="ln">   388  </span>					logger.Infof(&#34;Shutdown command returned &#39;signal: terminated&#39; error. Ignoring it.&#34;)
<span id="L389" class="ln">   389  </span>				} else {
<span id="L390" class="ln">   390  </span>					logger.Errorf(&#34;Couldn&#39;t shut down instance: %s&#34;, err)
<span id="L391" class="ln">   391  </span>					metrics.Increment(&#34;ErrorRate&#34;)
<span id="L392" class="ln">   392  </span>				}
<span id="L393" class="ln">   393  </span>			}
<span id="L394" class="ln">   394  </span>		}
<span id="L395" class="ln">   395  </span>
<span id="L396" class="ln">   396  </span>		os.Exit(0)
<span id="L397" class="ln">   397  </span>	}()
<span id="L398" class="ln">   398  </span>
<span id="L399" class="ln">   399  </span>	<span class="comment">// Log the Git commit of the running executable</span>
<span id="L400" class="ln">   400  </span>	logger.Infof(&#34;Host Service Version: %s&#34;, metadata.GetGitCommit())
<span id="L401" class="ln">   401  </span>
<span id="L402" class="ln">   402  </span>	<span class="comment">// Initialize the database driver, if necessary (the `dbdriver` package</span>
<span id="L403" class="ln">   403  </span>	<span class="comment">// takes care of the &#34;if necessary&#34; part).</span>
<span id="L404" class="ln">   404  </span>	if err := dbdriver.Initialize(globalCtx, globalCancel, &amp;goroutineTracker); err != nil {
<span id="L405" class="ln">   405  </span>		logger.Panic(globalCancel, err)
<span id="L406" class="ln">   406  </span>	}
<span id="L407" class="ln">   407  </span>
<span id="L408" class="ln">   408  </span>	<span class="comment">// Log the instance name we&#39;re running on</span>
<span id="L409" class="ln">   409  </span>	instanceName, err := aws.GetInstanceName()
<span id="L410" class="ln">   410  </span>	if err != nil {
<span id="L411" class="ln">   411  </span>		logger.Panic(globalCancel, err)
<span id="L412" class="ln">   412  </span>	}
<span id="L413" class="ln">   413  </span>	logger.Infof(&#34;Running on instance name: %s&#34;, instanceName)
<span id="L414" class="ln">   414  </span>
<span id="L415" class="ln">   415  </span>	initializeAppArmor(globalCancel)
<span id="L416" class="ln">   416  </span>
<span id="L417" class="ln">   417  </span>	initializeFilesystem(globalCancel)
<span id="L418" class="ln">   418  </span>
<span id="L419" class="ln">   419  </span>	if err := dbdriver.RegisterInstance(); err != nil {
<span id="L420" class="ln">   420  </span>		<span class="comment">// If the instance starts up and sees its status as unresponsive or</span>
<span id="L421" class="ln">   421  </span>		<span class="comment">// draining, the backend doesn&#39;t want it anymore so we should shut down.</span>
<span id="L422" class="ln">   422  </span>
<span id="L423" class="ln">   423  </span>		<span class="comment">// TODO: make this a bit more robust</span>
<span id="L424" class="ln">   424  </span>		if !metadata.IsLocalEnv() &amp;&amp; strings.Contains(err.Error(), string(dbdriver.InstanceStatusDraining)) {
<span id="L425" class="ln">   425  </span>			logger.Infof(&#34;Instance wasn&#39;t registered in database because we found ourselves already marked draining. Shutting down.... Error: %s&#34;, err)
<span id="L426" class="ln">   426  </span>			shutdownInstanceOnExit = true
<span id="L427" class="ln">   427  </span>			globalCancel()
<span id="L428" class="ln">   428  </span>		} else {
<span id="L429" class="ln">   429  </span>			logger.Panic(globalCancel, err)
<span id="L430" class="ln">   430  </span>		}
<span id="L431" class="ln">   431  </span>	}
<span id="L432" class="ln">   432  </span>
<span id="L433" class="ln">   433  </span>	<span class="comment">// Start database subscription client</span>
<span id="L434" class="ln">   434  </span>	instanceID, err := aws.GetInstanceID()
<span id="L435" class="ln">   435  </span>	if err != nil {
<span id="L436" class="ln">   436  </span>		logger.Errorf(&#34;Can&#39;t get AWS Instance Name. Error: %s&#34;, err)
<span id="L437" class="ln">   437  </span>		metrics.Increment(&#34;ErrorRate&#34;)
<span id="L438" class="ln">   438  </span>	}
<span id="L439" class="ln">   439  </span>
<span id="L440" class="ln">   440  </span>	capacity, err := dbdriver.GetInstanceCapacity(string(instanceID))
<span id="L441" class="ln">   441  </span>	if err != nil {
<span id="L442" class="ln">   442  </span>		logger.Errorf(&#34;Failed to get capacity of instance %v. Err: %s&#34;, instanceID, err)
<span id="L443" class="ln">   443  </span>	}
<span id="L444" class="ln">   444  </span>
<span id="L445" class="ln">   445  </span>	<span class="comment">// Now we start all the goroutines that actually do work.</span>
<span id="L446" class="ln">   446  </span>
<span id="L447" class="ln">   447  </span>	<span class="comment">// Start the HTTP server and listen for events</span>
<span id="L448" class="ln">   448  </span>	httpServerEvents, err := StartHTTPServer(globalCtx, globalCancel, &amp;goroutineTracker)
<span id="L449" class="ln">   449  </span>	if err != nil {
<span id="L450" class="ln">   450  </span>		logger.Panic(globalCancel, err)
<span id="L451" class="ln">   451  </span>	}
<span id="L452" class="ln">   452  </span>
<span id="L453" class="ln">   453  </span>	subscriptionEvents := make(chan subscriptions.SubscriptionEvent, 100)
<span id="L454" class="ln">   454  </span>	<span class="comment">// It&#39;s not necessary to subscribe to the config database</span>
<span id="L455" class="ln">   455  </span>	<span class="comment">// in the host service</span>
<span id="L456" class="ln">   456  </span>	useConfigDB := false
<span id="L457" class="ln">   457  </span>
<span id="L458" class="ln">   458  </span>	subscriptionClient := &amp;subscriptions.SubscriptionClient{}
<span id="L459" class="ln">   459  </span>	subscriptions.SetupHostSubscriptions(string(instanceID), subscriptionClient)
<span id="L460" class="ln">   460  </span>	subscriptions.Start(subscriptionClient, globalCtx, &amp;goroutineTracker, subscriptionEvents, useConfigDB)
<span id="L461" class="ln">   461  </span>	if err != nil {
<span id="L462" class="ln">   462  </span>		logger.Errorf(&#34;Failed to start database subscriptions. Error: %s&#34;, err)
<span id="L463" class="ln">   463  </span>	}
<span id="L464" class="ln">   464  </span>
<span id="L465" class="ln">   465  </span>	<span class="comment">// Start warming up as many instances as we have capacity for. This will effectively create</span>
<span id="L466" class="ln">   466  </span>	<span class="comment">// mandelboxes up to the point where we need a config token, and register them to the database.</span>
<span id="L467" class="ln">   467  </span>	<span class="comment">// The scaling service will handling assigning users to this instance and will update the</span>
<span id="L468" class="ln">   468  </span>	<span class="comment">// database row to assign the user to a waiting mandelbox.</span>
<span id="L469" class="ln">   469  </span>	SpinUpMandelboxes(globalCtx, globalCancel, &amp;goroutineTracker, dockerClient, string(instanceID), capacity)
<span id="L470" class="ln">   470  </span>
<span id="L471" class="ln">   471  </span>	<span class="comment">// Start main event loop. Note that we don&#39;t track this goroutine, but</span>
<span id="L472" class="ln">   472  </span>	<span class="comment">// instead control its lifetime with `eventLoopKeepAlive`. This is because it</span>
<span id="L473" class="ln">   473  </span>	<span class="comment">// needs to stay alive after the global context is cancelled, so we can</span>
<span id="L474" class="ln">   474  </span>	<span class="comment">// process mandelbox death events.</span>
<span id="L475" class="ln">   475  </span>	go eventLoopGoroutine(globalCtx, globalCancel, &amp;goroutineTracker, dockerClient, httpServerEvents, subscriptionEvents)
<span id="L476" class="ln">   476  </span>
<span id="L477" class="ln">   477  </span>	<span class="comment">// Register a signal handler for Ctrl-C so that we cleanup if Ctrl-C is pressed.</span>
<span id="L478" class="ln">   478  </span>	sigChan := make(chan os.Signal, 2)
<span id="L479" class="ln">   479  </span>	signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM, syscall.SIGINT)
<span id="L480" class="ln">   480  </span>
<span id="L481" class="ln">   481  </span>	<span class="comment">// Wait for either the global context to get cancelled by a worker goroutine,</span>
<span id="L482" class="ln">   482  </span>	<span class="comment">// or for us to receive an interrupt. This needs to be the end of main().</span>
<span id="L483" class="ln">   483  </span>	select {
<span id="L484" class="ln">   484  </span>	case &lt;-sigChan:
<span id="L485" class="ln">   485  </span>		logger.Infof(&#34;Got an interrupt or SIGTERM&#34;)
<span id="L486" class="ln">   486  </span>	case &lt;-globalCtx.Done():
<span id="L487" class="ln">   487  </span>		logger.Infof(&#34;Global context cancelled!&#34;)
<span id="L488" class="ln">   488  </span>	}
<span id="L489" class="ln">   489  </span>}
<span id="L490" class="ln">   490  </span>
<span id="L491" class="ln">   491  </span><span class="comment">// As long as this channel is blocking, we continue processing events</span>
<span id="L492" class="ln">   492  </span><span class="comment">// (including Docker events).</span>
<span id="L493" class="ln">   493  </span>var eventLoopKeepalive = make(chan interface{}, 1)
<span id="L494" class="ln">   494  </span>
<span id="L495" class="ln">   495  </span>func eventLoopGoroutine(globalCtx context.Context, globalCancel context.CancelFunc,
<span id="L496" class="ln">   496  </span>	goroutineTracker *sync.WaitGroup, dockerClient dockerclient.CommonAPIClient,
<span id="L497" class="ln">   497  </span>	httpServerEvents &lt;-chan httputils.ServerRequest, subscriptionEvents &lt;-chan subscriptions.SubscriptionEvent) {
<span id="L498" class="ln">   498  </span>	<span class="comment">// Note that we don&#39;t use globalCtx for the Docker Context, since we still</span>
<span id="L499" class="ln">   499  </span>	<span class="comment">// wish to process Docker events after the global context is cancelled.</span>
<span id="L500" class="ln">   500  </span>	dockerContext, dockerContextCancel := context.WithCancel(context.Background())
<span id="L501" class="ln">   501  </span>	defer dockerContextCancel()
<span id="L502" class="ln">   502  </span>
<span id="L503" class="ln">   503  </span>	<span class="comment">// Create filter for which docker events we care about</span>
<span id="L504" class="ln">   504  </span>	filters := dockerfilters.NewArgs()
<span id="L505" class="ln">   505  </span>	filters.Add(&#34;type&#34;, dockerevents.ContainerEventType)
<span id="L506" class="ln">   506  </span>	eventOptions := dockertypes.EventsOptions{
<span id="L507" class="ln">   507  </span>		Filters: filters,
<span id="L508" class="ln">   508  </span>	}
<span id="L509" class="ln">   509  </span>
<span id="L510" class="ln">   510  </span>	<span class="comment">// We use this lock to protect the transportRequestMap</span>
<span id="L511" class="ln">   511  </span>	transportMapLock := &amp;sync.Mutex{}
<span id="L512" class="ln">   512  </span>
<span id="L513" class="ln">   513  </span>	<span class="comment">// Note: If a mandelbox suffers a bug, or fails to start correctly</span>
<span id="L514" class="ln">   514  </span>	<span class="comment">// these channels will become a memory leak.</span>
<span id="L515" class="ln">   515  </span>	transportRequestMap := make(map[mandelboxtypes.MandelboxID]chan *httputils.JSONTransportRequest)
<span id="L516" class="ln">   516  </span>
<span id="L517" class="ln">   517  </span>	<span class="comment">// In the following loop, this var determines whether to re-initialize the</span>
<span id="L518" class="ln">   518  </span>	<span class="comment">// Docker event stream. This is necessary because the Docker event stream</span>
<span id="L519" class="ln">   519  </span>	<span class="comment">// needs to be reopened after any error is sent over the error channel.</span>
<span id="L520" class="ln">   520  </span>	needToReinitDockerEventStream := false
<span id="L521" class="ln">   521  </span>	dockerevents, dockererrs := dockerClient.Events(dockerContext, eventOptions)
<span id="L522" class="ln">   522  </span>	logger.Info(&#34;Initialized docker event stream.&#34;)
<span id="L523" class="ln">   523  </span>
<span id="L524" class="ln">   524  </span>	logger.Info(&#34;Entering event loop...&#34;)
<span id="L525" class="ln">   525  </span>
<span id="L526" class="ln">   526  </span>	<span class="comment">// The actual event loop</span>
<span id="L527" class="ln">   527  </span>	for {
<span id="L528" class="ln">   528  </span>		if needToReinitDockerEventStream {
<span id="L529" class="ln">   529  </span>			dockerevents, dockererrs = dockerClient.Events(dockerContext, eventOptions)
<span id="L530" class="ln">   530  </span>			needToReinitDockerEventStream = false
<span id="L531" class="ln">   531  </span>			logger.Info(&#34;Re-initialized docker event stream.&#34;)
<span id="L532" class="ln">   532  </span>		}
<span id="L533" class="ln">   533  </span>
<span id="L534" class="ln">   534  </span>		select {
<span id="L535" class="ln">   535  </span>		case &lt;-eventLoopKeepalive:
<span id="L536" class="ln">   536  </span>			logger.Infof(&#34;Leaving main event loop...&#34;)
<span id="L537" class="ln">   537  </span>			return
<span id="L538" class="ln">   538  </span>
<span id="L539" class="ln">   539  </span>		case err := &lt;-dockererrs:
<span id="L540" class="ln">   540  </span>			needToReinitDockerEventStream = true
<span id="L541" class="ln">   541  </span>			switch {
<span id="L542" class="ln">   542  </span>			case err == nil:
<span id="L543" class="ln">   543  </span>				logger.Info(&#34;We got a nil error over the Docker event stream. This might indicate an error inside the docker go library. Ignoring it and proceeding normally...&#34;)
<span id="L544" class="ln">   544  </span>				continue
<span id="L545" class="ln">   545  </span>			case err == io.EOF:
<span id="L546" class="ln">   546  </span>				logger.Panicf(globalCancel, &#34;Docker event stream has been completely read.&#34;)
<span id="L547" class="ln">   547  </span>			case dockerclient.IsErrConnectionFailed(err):
<span id="L548" class="ln">   548  </span>				<span class="comment">// This means &#34;Cannot connect to the Docker daemon...&#34;</span>
<span id="L549" class="ln">   549  </span>				logger.Panicf(globalCancel, &#34;Got error \&#34;%v\&#34;. Could not connect to the Docker daemon.&#34;, err)
<span id="L550" class="ln">   550  </span>			default:
<span id="L551" class="ln">   551  </span>				if !strings.HasSuffix(strings.ToLower(err.Error()), &#34;context canceled&#34;) {
<span id="L552" class="ln">   552  </span>					logger.Panicf(globalCancel, &#34;Got an unknown error from the Docker event stream: %v&#34;, err)
<span id="L553" class="ln">   553  </span>				}
<span id="L554" class="ln">   554  </span>				return
<span id="L555" class="ln">   555  </span>			}
<span id="L556" class="ln">   556  </span>
<span id="L557" class="ln">   557  </span>		case dockerevent := &lt;-dockerevents:
<span id="L558" class="ln">   558  </span>			logger.Infof(&#34;dockerevent: %s for %s %s\n&#34;, dockerevent.Action, dockerevent.Type, dockerevent.ID)
<span id="L559" class="ln">   559  </span>			if dockerevent.Action == &#34;die&#34; {
<span id="L560" class="ln">   560  </span>				mandelboxDieHandler(dockerevent.ID, transportRequestMap, transportMapLock, dockerClient)
<span id="L561" class="ln">   561  </span>			}
<span id="L562" class="ln">   562  </span>
<span id="L563" class="ln">   563  </span>		<span class="comment">// It may seem silly to just launch goroutines to handle these</span>
<span id="L564" class="ln">   564  </span>		<span class="comment">// serverevents, but we aim to keep the high-level flow control and handling</span>
<span id="L565" class="ln">   565  </span>		<span class="comment">// in this package, and the low-level authentication, parsing, etc. of</span>
<span id="L566" class="ln">   566  </span>		<span class="comment">// requests in `httpserver`.</span>
<span id="L567" class="ln">   567  </span>		case serverevent := &lt;-httpServerEvents:
<span id="L568" class="ln">   568  </span>			switch serverevent := serverevent.(type) {
<span id="L569" class="ln">   569  </span>			<span class="comment">// TODO: actually handle panics in these goroutines</span>
<span id="L570" class="ln">   570  </span>			case *httputils.JSONTransportRequest:
<span id="L571" class="ln">   571  </span>				if !metadata.IsLocalEnvWithoutDB() {
<span id="L572" class="ln">   572  </span>					<span class="comment">// Handle JSON transport validation on a separate goroutine</span>
<span id="L573" class="ln">   573  </span>					go handleJSONTransportRequest(serverevent, transportRequestMap, transportMapLock)
<span id="L574" class="ln">   574  </span>				} else {
<span id="L575" class="ln">   575  </span>					<span class="comment">// If running on a local environment, disable any pubsub logic. We have to create a subscription request</span>
<span id="L576" class="ln">   576  </span>					<span class="comment">// that mocks the Hasura subscription event. Doing this avoids the need of setting up a Hasura server and</span>
<span id="L577" class="ln">   577  </span>					<span class="comment">// postgres database on the development instance.</span>
<span id="L578" class="ln">   578  </span>					jsonReq := serverevent
<span id="L579" class="ln">   579  </span>
<span id="L580" class="ln">   580  </span>					userID, err := metadata.GetUserID()
<span id="L581" class="ln">   581  </span>					if err != nil {
<span id="L582" class="ln">   582  </span>						logger.Errorf(&#34;Error getting userID, %v&#34;, err)
<span id="L583" class="ln">   583  </span>						metrics.Increment(&#34;ErrorRate&#34;)
<span id="L584" class="ln">   584  </span>					}
<span id="L585" class="ln">   585  </span>
<span id="L586" class="ln">   586  </span>					instanceID, err := aws.GetInstanceID()
<span id="L587" class="ln">   587  </span>					if err != nil {
<span id="L588" class="ln">   588  </span>						logger.Errorf(&#34;Error getting instance name from AWS, %v&#34;, err)
<span id="L589" class="ln">   589  </span>						metrics.Increment(&#34;ErrorRate&#34;)
<span id="L590" class="ln">   590  </span>					}
<span id="L591" class="ln">   591  </span>
<span id="L592" class="ln">   592  </span>					<span class="comment">// Create a mandelbox object as would be received from a Hasura subscription.</span>
<span id="L593" class="ln">   593  </span>					mandelbox := subscriptions.Mandelbox{
<span id="L594" class="ln">   594  </span>						InstanceID: string(instanceID),
<span id="L595" class="ln">   595  </span>						ID:         jsonReq.MandelboxID,
<span id="L596" class="ln">   596  </span>						SessionID:  utils.Sprintf(&#34;%v&#34;, time.Now().UnixMilli()),
<span id="L597" class="ln">   597  </span>						UserID:     userID,
<span id="L598" class="ln">   598  </span>					}
<span id="L599" class="ln">   599  </span>					subscriptionEvent := subscriptions.MandelboxEvent{
<span id="L600" class="ln">   600  </span>						Mandelboxes: []subscriptions.Mandelbox{mandelbox},
<span id="L601" class="ln">   601  </span>					}
<span id="L602" class="ln">   602  </span>					<span class="comment">// mandelboxSubscription is the pubsub event received from Hasura.</span>
<span id="L603" class="ln">   603  </span>					mandelboxSubscription := subscriptionEvent.Mandelboxes[0]
<span id="L604" class="ln">   604  </span>
<span id="L605" class="ln">   605  </span>					<span class="comment">// Launch the JSON transport handler to be able to call getAppName and obtain appName and req, needed to spin up the mandelbox.</span>
<span id="L606" class="ln">   606  </span>					go handleJSONTransportRequest(serverevent, transportRequestMap, transportMapLock)
<span id="L607" class="ln">   607  </span>					req, appName := getAppName(mandelboxSubscription, transportRequestMap, transportMapLock)
<span id="L608" class="ln">   608  </span>
<span id="L609" class="ln">   609  </span>					<span class="comment">// For local development, we start and finish the mandelbox spin up back to back</span>
<span id="L610" class="ln">   610  </span>					StartMandelboxSpinUp(globalCtx, globalCancel, goroutineTracker, dockerClient, jsonReq.MandelboxID, appName)
<span id="L611" class="ln">   611  </span>					go FinishMandelboxSpinUp(globalCtx, globalCancel, goroutineTracker, dockerClient, mandelboxSubscription, transportRequestMap, transportMapLock, req)
<span id="L612" class="ln">   612  </span>				}
<span id="L613" class="ln">   613  </span>			default:
<span id="L614" class="ln">   614  </span>				if serverevent != nil {
<span id="L615" class="ln">   615  </span>					err := utils.MakeError(&#34;unimplemented handling of server event [type: %T]: %v&#34;, serverevent, serverevent)
<span id="L616" class="ln">   616  </span>					logger.Error(err)
<span id="L617" class="ln">   617  </span>					serverevent.ReturnResult(&#34;&#34;, err)
<span id="L618" class="ln">   618  </span>				}
<span id="L619" class="ln">   619  </span>			}
<span id="L620" class="ln">   620  </span>
<span id="L621" class="ln">   621  </span>		case subscriptionEvent := &lt;-subscriptionEvents:
<span id="L622" class="ln">   622  </span>			switch subscriptionEvent := subscriptionEvent.(type) {
<span id="L623" class="ln">   623  </span>			<span class="comment">// TODO: actually handle panics in these goroutines</span>
<span id="L624" class="ln">   624  </span>			case *subscriptions.MandelboxEvent:
<span id="L625" class="ln">   625  </span>				mandelboxSubscription := subscriptionEvent.Mandelboxes[0]
<span id="L626" class="ln">   626  </span>				req, _ := getAppName(mandelboxSubscription, transportRequestMap, transportMapLock)
<span id="L627" class="ln">   627  </span>				go FinishMandelboxSpinUp(globalCtx, globalCancel, goroutineTracker, dockerClient,
<span id="L628" class="ln">   628  </span>					mandelboxSubscription, transportRequestMap, transportMapLock, req)
<span id="L629" class="ln">   629  </span>
<span id="L630" class="ln">   630  </span>			case *subscriptions.InstanceEvent:
<span id="L631" class="ln">   631  </span>				if len(subscriptionEvent.Instances) == 0 {
<span id="L632" class="ln">   632  </span>					break
<span id="L633" class="ln">   633  </span>				}
<span id="L634" class="ln">   634  </span>				instance := subscriptionEvent.Instances[0]
<span id="L635" class="ln">   635  </span>
<span id="L636" class="ln">   636  </span>				<span class="comment">// If the status of the instance changes to &#34;DRAINING&#34;, cancel the global context and exit.</span>
<span id="L637" class="ln">   637  </span>				if instance.Status == string(dbdriver.InstanceStatusDraining) {
<span id="L638" class="ln">   638  </span>					<span class="comment">// Don&#39;t do this in a separate goroutine, since there&#39;s no reason to.</span>
<span id="L639" class="ln">   639  </span>					drainAndShutdown(globalCtx, globalCancel, goroutineTracker)
<span id="L640" class="ln">   640  </span>					break
<span id="L641" class="ln">   641  </span>				}
<span id="L642" class="ln">   642  </span>
<span id="L643" class="ln">   643  </span>				logger.Infof(&#34;Instance has a remaining capacity of %v, current number of waiting mandelboxes is %v&#34;, instance.RemainingCapacity, mandelboxData.GetMandelboxCount())
<span id="L644" class="ln">   644  </span>
<span id="L645" class="ln">   645  </span>				newWaitingMandelboxes := int32(instance.RemainingCapacity) - mandelboxData.GetMandelboxCount()
<span id="L646" class="ln">   646  </span>				<span class="comment">// If the remaining capacity field changes, check how many mandelboxes are currently</span>
<span id="L647" class="ln">   647  </span>				<span class="comment">// running and start mandelbox zygotes as necessary.</span>
<span id="L648" class="ln">   648  </span>				if newWaitingMandelboxes &gt; 0 {
<span id="L649" class="ln">   649  </span>					logger.Infof(&#34;Starting %v new waiting mandelboxes.&#34;, newWaitingMandelboxes)
<span id="L650" class="ln">   650  </span>					SpinUpMandelboxes(globalCtx, globalCancel, goroutineTracker, dockerClient, instance.ID, newWaitingMandelboxes)
<span id="L651" class="ln">   651  </span>				}
<span id="L652" class="ln">   652  </span>
<span id="L653" class="ln">   653  </span>			default:
<span id="L654" class="ln">   654  </span>				if subscriptionEvent != nil {
<span id="L655" class="ln">   655  </span>					err := utils.MakeError(&#34;Unimplemented handling of subscription event [type: %T]: %v&#34;, subscriptionEvent, subscriptionEvent)
<span id="L656" class="ln">   656  </span>					logger.Error(err)
<span id="L657" class="ln">   657  </span>				}
<span id="L658" class="ln">   658  </span>			}
<span id="L659" class="ln">   659  </span>		}
<span id="L660" class="ln">   660  </span>	}
<span id="L661" class="ln">   661  </span>}
<span id="L662" class="ln">   662  </span>
</pre><p></p>

<div id="footer">
Build version go1.18.3.<br/>
</div>

</div><!-- .container -->
</div><!-- #page -->


</body></html>